{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampler import ImbalancedDatasetSampler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImgFolder='data/bihar/bihar_2010_landsat7_cutFiles_rgb_BF_train/'\n",
    "testImgFolder='data/bihar/bihar_2010_landsat7_cutFiles_rgb_BF_test/'\n",
    "checkPtFolder=trainImgFolder[:-1]+'_checkpoints'\n",
    "os.makedirs(checkPtFolder, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 30\n",
    "num_classes = 3\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "myTransform = transforms.Compose(\n",
    "                   [transforms.Resize((64,64)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.65, 0.65, 0.65), (0.15, 0.15, 0.15))])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=trainImgFolder,\n",
    "                                                transform=myTransform)\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=testImgFolder,\n",
    "                                               transform=myTransform)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=ImbalancedDatasetSampler(train_dataset))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(16*16*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/315], Loss: 0.9840\n",
      "Epoch [1/30], Step [200/315], Loss: 1.0348\n",
      "Epoch [1/30], Step [300/315], Loss: 0.7885\n",
      "Epoch [2/30], Step [100/315], Loss: 0.6728\n",
      "Epoch [2/30], Step [200/315], Loss: 0.5204\n",
      "Epoch [2/30], Step [300/315], Loss: 0.4625\n",
      "Epoch [3/30], Step [100/315], Loss: 0.5297\n",
      "Epoch [3/30], Step [200/315], Loss: 0.4521\n",
      "Epoch [3/30], Step [300/315], Loss: 0.3258\n",
      "Epoch [4/30], Step [100/315], Loss: 0.3448\n",
      "Epoch [4/30], Step [200/315], Loss: 0.2341\n",
      "Epoch [4/30], Step [300/315], Loss: 0.3502\n",
      "Epoch [5/30], Step [100/315], Loss: 0.2979\n",
      "Epoch [5/30], Step [200/315], Loss: 0.3275\n",
      "Epoch [5/30], Step [300/315], Loss: 0.2028\n",
      "Epoch [6/30], Step [100/315], Loss: 0.1279\n",
      "Epoch [6/30], Step [200/315], Loss: 0.2275\n",
      "Epoch [6/30], Step [300/315], Loss: 0.2324\n",
      "Epoch [7/30], Step [100/315], Loss: 0.1859\n",
      "Epoch [7/30], Step [200/315], Loss: 0.1575\n",
      "Epoch [7/30], Step [300/315], Loss: 0.1972\n",
      "Epoch [8/30], Step [100/315], Loss: 0.1166\n",
      "Epoch [8/30], Step [200/315], Loss: 0.1975\n",
      "Epoch [8/30], Step [300/315], Loss: 0.1877\n",
      "Epoch [9/30], Step [100/315], Loss: 0.1182\n",
      "Epoch [9/30], Step [200/315], Loss: 0.0902\n",
      "Epoch [9/30], Step [300/315], Loss: 0.0960\n",
      "Epoch [10/30], Step [100/315], Loss: 0.0502\n",
      "Epoch [10/30], Step [200/315], Loss: 0.0717\n",
      "Epoch [10/30], Step [300/315], Loss: 0.0897\n",
      "Epoch [11/30], Step [100/315], Loss: 0.0649\n",
      "Epoch [11/30], Step [200/315], Loss: 0.0796\n",
      "Epoch [11/30], Step [300/315], Loss: 0.0504\n",
      "Epoch [12/30], Step [100/315], Loss: 0.0771\n",
      "Epoch [12/30], Step [200/315], Loss: 0.1005\n",
      "Epoch [12/30], Step [300/315], Loss: 0.1150\n",
      "Epoch [13/30], Step [100/315], Loss: 0.0535\n",
      "Epoch [13/30], Step [200/315], Loss: 0.0598\n",
      "Epoch [13/30], Step [300/315], Loss: 0.0694\n",
      "Epoch [14/30], Step [100/315], Loss: 0.1282\n",
      "Epoch [14/30], Step [200/315], Loss: 0.0545\n",
      "Epoch [14/30], Step [300/315], Loss: 0.0339\n",
      "Epoch [15/30], Step [100/315], Loss: 0.0582\n",
      "Epoch [15/30], Step [200/315], Loss: 0.0735\n",
      "Epoch [15/30], Step [300/315], Loss: 0.0194\n",
      "Epoch [16/30], Step [100/315], Loss: 0.0800\n",
      "Epoch [16/30], Step [200/315], Loss: 0.0166\n",
      "Epoch [16/30], Step [300/315], Loss: 0.0251\n",
      "Epoch [17/30], Step [100/315], Loss: 0.1348\n",
      "Epoch [17/30], Step [200/315], Loss: 0.0779\n",
      "Epoch [17/30], Step [300/315], Loss: 0.0597\n",
      "Epoch [18/30], Step [100/315], Loss: 0.0539\n",
      "Epoch [18/30], Step [200/315], Loss: 0.0162\n",
      "Epoch [18/30], Step [300/315], Loss: 0.0396\n",
      "Epoch [19/30], Step [100/315], Loss: 0.0456\n",
      "Epoch [19/30], Step [200/315], Loss: 0.0162\n",
      "Epoch [19/30], Step [300/315], Loss: 0.0160\n",
      "Epoch [20/30], Step [100/315], Loss: 0.0506\n",
      "Epoch [20/30], Step [200/315], Loss: 0.0314\n",
      "Epoch [20/30], Step [300/315], Loss: 0.0302\n",
      "Epoch [21/30], Step [100/315], Loss: 0.0146\n",
      "Epoch [21/30], Step [200/315], Loss: 0.0737\n",
      "Epoch [21/30], Step [300/315], Loss: 0.0225\n",
      "Epoch [22/30], Step [100/315], Loss: 0.0127\n",
      "Epoch [22/30], Step [200/315], Loss: 0.0565\n",
      "Epoch [22/30], Step [300/315], Loss: 0.0368\n",
      "Epoch [23/30], Step [100/315], Loss: 0.0844\n",
      "Epoch [23/30], Step [200/315], Loss: 0.0628\n",
      "Epoch [23/30], Step [300/315], Loss: 0.0176\n",
      "Epoch [24/30], Step [100/315], Loss: 0.0090\n",
      "Epoch [24/30], Step [200/315], Loss: 0.0160\n",
      "Epoch [24/30], Step [300/315], Loss: 0.0381\n",
      "Epoch [25/30], Step [100/315], Loss: 0.0777\n",
      "Epoch [25/30], Step [200/315], Loss: 0.0066\n",
      "Epoch [25/30], Step [300/315], Loss: 0.0462\n",
      "Epoch [26/30], Step [100/315], Loss: 0.0207\n",
      "Epoch [26/30], Step [200/315], Loss: 0.0487\n",
      "Epoch [26/30], Step [300/315], Loss: 0.0122\n",
      "Epoch [27/30], Step [100/315], Loss: 0.0158\n",
      "Epoch [27/30], Step [200/315], Loss: 0.0315\n",
      "Epoch [27/30], Step [300/315], Loss: 0.0115\n",
      "Epoch [28/30], Step [100/315], Loss: 0.0577\n",
      "Epoch [28/30], Step [200/315], Loss: 0.0608\n",
      "Epoch [28/30], Step [300/315], Loss: 0.0389\n",
      "Epoch [29/30], Step [100/315], Loss: 0.0299\n",
      "Epoch [29/30], Step [200/315], Loss: 0.0169\n",
      "Epoch [29/30], Step [300/315], Loss: 0.0122\n",
      "Epoch [30/30], Step [100/315], Loss: 0.0126\n",
      "Epoch [30/30], Step [200/315], Loss: 0.0082\n",
      "Epoch [30/30], Step [300/315], Loss: 0.0294\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    file_name=checkPtFolder+'/'+'epoch_'+str(epoch)+'.ckpt'\n",
    "    torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Counter({2: 5751, 0: 1174, 1: 939})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9633730834752982\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.010649627263045794\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.048861067640410365\n",
      "====================\n",
      "f1_weighted 0.2528718133604624\n",
      "f1_macro 0.12479639882523152\n",
      "f1_micro 0.18082400813835195\n",
      "========================================\n",
      "Counter({0: 4846, 2: 2564, 1: 454})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9546017333883615\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.01762114537444934\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.05382215288611544\n",
      "====================\n",
      "f1_weighted 0.7174947273264641\n",
      "f1_macro 0.2928182346083111\n",
      "f1_micro 0.6068158697863683\n",
      "========================================\n",
      "Counter({0: 6972, 2: 791, 1: 101})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9519506597819851\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0297029702970297\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07332490518331226\n",
      "====================\n",
      "f1_weighted 0.8770057220872335\n",
      "f1_macro 0.35372713774793496\n",
      "f1_micro 0.8517293997965412\n",
      "========================================\n",
      "Counter({0: 5183, 2: 2623, 1: 58})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.958904109589041\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.017241379310344827\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06519252764010675\n",
      "====================\n",
      "f1_weighted 0.7509422380573022\n",
      "f1_macro 0.3067283704092592\n",
      "f1_micro 0.6538657171922686\n",
      "========================================\n",
      "Counter({0: 4094, 2: 3624, 1: 146})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.95847581827064\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0136986301369863\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.05601545253863135\n",
      "====================\n",
      "f1_weighted 0.6489719336981997\n",
      "f1_macro 0.26739595287666174\n",
      "f1_micro 0.5250508646998983\n",
      "========================================\n",
      "Counter({0: 7233, 2: 597, 1: 34})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9518871837411862\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.029411764705882353\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.08542713567839195\n",
      "====================\n",
      "f1_weighted 0.8936844218308354\n",
      "f1_macro 0.35615282290779743\n",
      "f1_micro 0.8821210579857579\n",
      "========================================\n",
      "Counter({0: 6597, 2: 1202, 1: 65})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9552827042595119\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.03076923076923077\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07820299500831947\n",
      "====================\n",
      "f1_weighted 0.8559674718468862\n",
      "f1_macro 0.3509490739388068\n",
      "f1_micro 0.8135808748728383\n",
      "========================================\n",
      "Counter({0: 7424, 2: 370, 1: 70})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9508351293103449\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.02857142857142857\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.08648648648648649\n",
      "====================\n",
      "f1_weighted 0.9036248081311669\n",
      "f1_macro 0.35678771473487053\n",
      "f1_micro 0.9019582909460834\n",
      "========================================\n",
      "Counter({0: 6205, 2: 1613, 1: 46})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9571313456889605\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.021739130434782608\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07563546187228766\n",
      "====================\n",
      "f1_weighted 0.8300625152187315\n",
      "f1_macro 0.3381993833354897\n",
      "f1_micro 0.7708545269582909\n",
      "========================================\n",
      "Counter({0: 7322, 2: 509, 1: 33})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9501502321770008\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07465618860510806\n",
      "====================\n",
      "f1_weighted 0.8965375732940005\n",
      "f1_macro 0.34292733887270493\n",
      "f1_micro 0.8894964394710071\n",
      "========================================\n",
      "Counter({0: 6727, 2: 1108, 1: 29})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9530251226401071\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.0703971119133574\n",
      "====================\n",
      "f1_weighted 0.8618784401202987\n",
      "f1_macro 0.3367365241920648\n",
      "f1_micro 0.8251525940996949\n",
      "========================================\n",
      "Counter({0: 7527, 2: 297, 1: 40})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9503122093795668\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.025\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.09764309764309764\n",
      "====================\n",
      "f1_weighted 0.9092935781284278\n",
      "f1_macro 0.3552470069838211\n",
      "f1_micro 0.9134028484231943\n",
      "========================================\n",
      "Counter({0: 7034, 2: 771, 1: 59})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9533693488768837\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.01694915254237288\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.0907911802853437\n",
      "====================\n",
      "f1_weighted 0.8832324054769521\n",
      "f1_macro 0.3560038276597189\n",
      "f1_micro 0.8617751780264497\n",
      "========================================\n",
      "Counter({0: 7148, 2: 658, 1: 58})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9517347509792949\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.017241379310344827\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.0729483282674772\n",
      "====================\n",
      "f1_weighted 0.8876137781363498\n",
      "f1_macro 0.34827835514934263\n",
      "f1_micro 0.8713123092573754\n",
      "========================================\n",
      "Counter({0: 7386, 2: 466, 1: 12})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.949905226103439\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07510729613733906\n",
      "====================\n",
      "f1_weighted 0.9000987971272014\n",
      "f1_macro 0.34331787693939037\n",
      "f1_micro 0.896617497456765\n",
      "========================================\n",
      "Counter({0: 7282, 2: 551, 1: 31})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9512496566877231\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.03225806451612903\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07078039927404718\n",
      "====================\n",
      "f1_weighted 0.8951707304407474\n",
      "f1_macro 0.35036577024038573\n",
      "f1_micro 0.8859359104781281\n",
      "========================================\n",
      "Counter({0: 7198, 2: 640, 1: 26})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9517921644901361\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.038461538461538464\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.08125\n",
      "====================\n",
      "f1_weighted 0.8913064851512138\n",
      "f1_macro 0.35540306068776717\n",
      "f1_micro 0.8779247202441505\n",
      "========================================\n",
      "Counter({0: 7241, 2: 574, 1: 49})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9500069051236018\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.02040816326530612\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06968641114982578\n",
      "====================\n",
      "f1_weighted 0.8914384281604697\n",
      "f1_macro 0.3474739035480398\n",
      "f1_micro 0.8799593082400814\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7408, 2: 437, 1: 19})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9500539956803455\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.05263157894736842\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07322654462242563\n",
      "====================\n",
      "f1_weighted 0.9015538370178608\n",
      "f1_macro 0.3524601101011417\n",
      "f1_micro 0.8991607324516785\n",
      "========================================\n",
      "Counter({0: 7160, 2: 688, 1: 16})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9506983240223463\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07122093023255814\n",
      "====================\n",
      "f1_weighted 0.8872575598482262\n",
      "f1_macro 0.3415973692886094\n",
      "f1_micro 0.8718209562563581\n",
      "========================================\n",
      "Counter({0: 7206, 2: 593, 1: 65})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9503191784623924\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.015384615384615385\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06913996627318718\n",
      "====================\n",
      "f1_weighted 0.8895492471686837\n",
      "f1_macro 0.3459493809040752\n",
      "f1_micro 0.876144455747711\n",
      "========================================\n",
      "Counter({0: 7504, 2: 349, 1: 11})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9506929637526652\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.09169054441260745\n",
      "====================\n",
      "f1_weighted 0.908233453606438\n",
      "f1_macro 0.34789872779449443\n",
      "f1_micro 0.9112410986775178\n",
      "========================================\n",
      "Counter({0: 7512, 2: 281, 1: 71})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9488817891373802\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.014084507042253521\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06405693950177936\n",
      "====================\n",
      "f1_weighted 0.9055201573038473\n",
      "f1_macro 0.34179529751086085\n",
      "f1_micro 0.90882502543235\n",
      "========================================\n",
      "Counter({0: 7451, 2: 391, 1: 22})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9498053952489599\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.045454545454545456\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06905370843989769\n",
      "====================\n",
      "f1_weighted 0.9035282850795374\n",
      "f1_macro 0.3500622082875659\n",
      "f1_micro 0.9034842319430315\n",
      "========================================\n",
      "Counter({0: 6999, 2: 798, 1: 67})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9507072438919846\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.014925373134328358\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06265664160401002\n",
      "====================\n",
      "f1_weighted 0.8768032631965911\n",
      "f1_macro 0.34148126182544974\n",
      "f1_micro 0.8526195320447608\n",
      "========================================\n",
      "Counter({0: 7519, 2: 334, 1: 11})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9499933501795451\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.08083832335329341\n",
      "====================\n",
      "f1_weighted 0.9078932452816142\n",
      "f1_macro 0.3438483449908789\n",
      "f1_micro 0.9117497456765005\n",
      "========================================\n",
      "Counter({0: 7618, 2: 237, 1: 9})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9486741927014964\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06751054852320675\n",
      "====================\n",
      "f1_weighted 0.91140113742607\n",
      "f1_macro 0.3374350131875328\n",
      "f1_micro 0.9210325534079349\n",
      "========================================\n",
      "Counter({0: 7276, 2: 567, 1: 21})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9512094557449148\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.0\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.08641975308641975\n",
      "====================\n",
      "f1_weighted 0.8955348679534387\n",
      "f1_macro 0.34834727527624815\n",
      "f1_micro 0.8863173957273652\n",
      "========================================\n",
      "Counter({0: 7458, 2: 374, 1: 32})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9486457495307052\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.03125\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.06149732620320856\n",
      "====================\n",
      "f1_weighted 0.9024040959652487\n",
      "f1_macro 0.34553697706403136\n",
      "f1_micro 0.9027212614445574\n",
      "========================================\n",
      "Counter({0: 7548, 2: 296, 1: 20})\n",
      "Counter({0: 7453, 2: 364, 1: 47})\n",
      "====================\n",
      "class 0  accuracy_score:  0.9491255961844197\n",
      "====================\n",
      "====================\n",
      "class 1  accuracy_score:  0.05\n",
      "====================\n",
      "====================\n",
      "class 2  accuracy_score:  0.07432432432432433\n",
      "====================\n",
      "f1_weighted 0.9084817747125703\n",
      "f1_macro 0.3505512457267912\n",
      "f1_micro 0.9139114954221771\n"
     ]
    }
   ],
   "source": [
    "for tk in range(num_epochs):\n",
    "    print('='*40)\n",
    "    file_name=checkPtFolder+'/'+'epoch_'+str(tk)+'.ckpt'\n",
    "    state_dict = torch.load(file_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        trueLabels=[]\n",
    "        predictedLabels=[]\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            trueLabels.extend(labels.tolist())\n",
    "            predictedLabels.extend(predicted.tolist())\n",
    "        print(Counter(predictedLabels))\n",
    "        print(Counter(trueLabels))\n",
    "        predictedLabels = np.array(predictedLabels)\n",
    "        trueLabels = np.array(trueLabels)\n",
    "        for currentClass in range(3):\n",
    "            print('='*20)\n",
    "            maskClass=(predictedLabels==currentClass)\n",
    "            print('class',currentClass,' accuracy_score: ',accuracy_score(predictedLabels[maskClass],trueLabels[maskClass]))\n",
    "            print('='*20)\n",
    "        print('f1_weighted',f1_score(trueLabels, predictedLabels, average='weighted'))\n",
    "        print('f1_macro',f1_score(trueLabels, predictedLabels, average='macro'))\n",
    "        print('f1_micro',f1_score(trueLabels, predictedLabels, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
