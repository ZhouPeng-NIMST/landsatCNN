{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampler import ImbalancedDatasetSampler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "from pytorch_image_folder_with_file_paths import ImageFolderWithPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFile = sys.argv[1]\n",
    "testImgFolder = sys.argv[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainImgFolder='data/bihar/bihar_2010_landsat7_cutFiles_rgb_BF_train/'\n",
    "#testImgFolder='data/bihar/bihar_2010_landsat7_cutFiles_rgb_BF_test/'\n",
    "\n",
    "#trainImgFolder = sys.argv[1]\n",
    "#checkPtFolder=trainImgFolder[:-1]+'_checkpoints'\n",
    "#os.makedirs(checkPtFolder, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 80\n",
    "num_classes = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "myTransform = transforms.Compose(\n",
    "                   [transforms.Resize((64,64)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.65, 0.65, 0.65), (0.15, 0.15, 0.15))])\n",
    "\n",
    "\n",
    "#train_dataset = torchvision.datasets.ImageFolder(root=trainImgFolder,\n",
    "#                                                transform=myTransform)\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=ImageFolderWithPaths(testImgFolder),\n",
    "                                               transform=myTransform)\n",
    "\n",
    "# Data loader\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                           batch_size=batch_size,\n",
    "#                                           sampler=ImbalancedDatasetSampler(train_dataset))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "model = models.resnet18(num_classes=num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "\n",
    "model = models.resnet18(num_classes=num_classes)\n",
    "for tk in range(num_epochs):\n",
    "    print('='*40)\n",
    "    file_name=modelFile\n",
    "    state_dict = torch.load(file_name)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        trueLabels=[]\n",
    "        imagesList=[]\n",
    "        predictedLabels=[]\n",
    "        for images, labels,paths in test_loader:\n",
    "            images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             trueLabels.extend(labels.tolist())\n",
    "            imagesList.extend(paths.tolist())\n",
    "            predictedLabels.extend(predicted.tolist())\n",
    "        print(Counter(predictedLabels))\n",
    "#         print(Counter(trueLabels))\n",
    "        predictedLabels = np.array(predictedLabels)\n",
    "#         trueLabels = np.array(trueLabels)\n",
    "#         for currentClass in range(3):\n",
    "#             print('='*20)\n",
    "#             maskClass=(predictedLabels==currentClass)\n",
    "#             print('class',currentClass,' accuracy_score: ',accuracy_score(predictedLabels[maskClass],trueLabels[maskClass]))\n",
    "#             print('='*20)\n",
    "#         print('f1_weighted',f1_score(trueLabels, predictedLabels, average='weighted'))\n",
    "#         print('f1_macro',f1_score(trueLabels, predictedLabels, average='macro'))\n",
    "#         print('f1_micro',f1_score(trueLabels, predictedLabels, average='micro'))\n",
    "    break\n",
    "    \n",
    "# print(predictedLabels)\n",
    "# print(imagesList)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
