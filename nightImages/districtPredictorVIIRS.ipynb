{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Image Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix code\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import product\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting normalize=True.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('')\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the ground truth labels and getting all the monthly bucket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath='normal_csvFiles/normal_csv/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# print(onlyfiles)\n",
    "labels_2011=pd.read_csv('2011_label.csv')\n",
    "array1=(labels_2011['EMP_2011'].values)\n",
    "df_emp_to_number={'Unemployment':1,'Agricultural':2,'Non Agri':3}\n",
    "array2=np.array([df_emp_to_number[t] for t in array1])\n",
    "labels_2011['numEMP_2011']=array2\n",
    "trainCols=['light_'+str(i) for i in range(0,101,1)]\n",
    "predictCols=['MSW_2011','BF_2011','MSL_2011','FC_2011','CHH_2011','numEMP_2011']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Balanced Weighted Random Forest and averaging out 5 times for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Month:  normal_viirs_India_2013-02-01_2013-02-28_500.csv\n",
      "For Month:  normal_viirs_India_2013-01-01_2013-01-31_500.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bda653aac10c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mscore_curr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 316\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[1;32m    127\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     58\u001b[0m                             % (repr(estimator), type(estimator)))\n\u001b[1;32m     59\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[1;32m    201\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0;32m--> 201\u001b[0;31m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_df = pd.DataFrame(columns=('Month','MSW_2011','BF_2011','MSL_2011','FC_2011','CHH_2011','numEMP_2011'))\n",
    "loc_int=0\n",
    "for csvFileName1 in onlyfiles:\n",
    "    rowToAppend=[csvFileName1[:-4]]\n",
    "    print('For Month: ', csvFileName1)\n",
    "    #csvFileName='corrected_csvFiles/corrected_csv/corrected_viirs_India_2014-01-01_2014-01-31_500.csv'\n",
    "    csvFileName=mypath+csvFileName1\n",
    "    viirsBucketsData=pd.read_csv(csvFileName)\n",
    "    viirsBucketsData.rename( columns={'Unnamed: 0':'dname'}, inplace=True)\n",
    "    combinedDf = pd.merge(viirsBucketsData, labels_2011, left_on=['censuscode'], right_on = ['District'])\n",
    "    for prediction_label in predictCols: \n",
    "        #print(prediction_label)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_features)\n",
    "        \n",
    "        list_acc=[]\n",
    "        for i in range(5):\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(combinedDf[trainCols], \n",
    "                                                                                        combinedDf[prediction_label],\n",
    "                                                                                        test_size = 0.3,\n",
    "                                                                                        random_state = int(random.random()))\n",
    "            \n",
    "            rf = RandomForestClassifier(n_estimators = 500, random_state = 64, class_weight='balanced')\n",
    "            rf.fit(scaler.transform(train_features), train_labels)\n",
    "            predictions = rf.predict(scaler.transform(test_features))\n",
    "            score_curr=f1_score(test_labels, predictions, average='weighted')\n",
    "            list_acc.append(score_curr)\n",
    "            \n",
    "        rowToAppend.append(mean(list_acc))    \n",
    "        \n",
    "    acc_df.loc[loc_int] = rowToAppend\n",
    "    loc_int+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Accuracy Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.to_csv('accuracy_normal_viirs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSW_2011\n",
      "accuracy_score 0.6243386243386243\n",
      "f1_score 0.6113506191673601\n",
      "\n",
      "BF_2011\n",
      "accuracy_score 0.671957671957672\n",
      "f1_score 0.6490028190511791\n",
      "\n",
      "MSL_2011\n",
      "accuracy_score 0.6666666666666666\n",
      "f1_score 0.6252304297414653\n",
      "\n",
      "FC_2011\n",
      "accuracy_score 0.708994708994709\n",
      "f1_score 0.6960127058662144\n",
      "\n",
      "CHH_2011\n",
      "accuracy_score 0.5978835978835979\n",
      "f1_score 0.5988872907010949\n",
      "\n",
      "numEMP_2011\n",
      "accuracy_score 0.6402116402116402\n",
      "f1_score 0.6439286587316017\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvFileName='corrected_csvFiles/corrected_csv/corrected_viirs_India_2014-12-01_2014-12-31_500.csv'\n",
    "viirsBucketsData=pd.read_csv(csvFileName)\n",
    "viirsBucketsData.rename( columns={'Unnamed: 0':'dname'}, inplace=True)\n",
    "combinedDf = pd.merge(viirsBucketsData, labels_2011, left_on=['censuscode'], right_on = ['District'])\n",
    "for prediction_label in predictCols: \n",
    "    print(prediction_label)\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(combinedDf[trainCols], \n",
    "                                                                                combinedDf[prediction_label],\n",
    "                                                                                test_size = 0.3,\n",
    "                                                                                random_state = 60)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "    rf = RandomForestClassifier(n_estimators = 500, random_state = 64, class_weight='balanced')\n",
    "    rf.fit(scaler.transform(train_features), train_labels)\n",
    "    predictions = rf.predict(scaler.transform(test_features))\n",
    "    print('accuracy_score',accuracy_score(test_labels, predictions))\n",
    "    print('f1_score',f1_score(test_labels, predictions,average='weighted'))\n",
    "    cnf_matrix = confusion_matrix(test_labels, predictions)\n",
    "    class_names=['1. Under-Developed','2. Moderately-Developed','3. Developed']\n",
    "    if(prediction_label=='numEMP_2011'):\n",
    "        class_names=['1. Unemployment','2. Agricultural','3. Non Agricultural Employment']\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title=prediction_label+'_Normalized')\n",
    "    plt.savefig(prediction_label+'_Normalized.jpg')\n",
    "    plt.clf()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=False,title=prediction_label+'_Absolute')\n",
    "    plt.savefig(prediction_label+'_Absolute.jpg')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4735752877613343\n",
      "#########################################\n",
      "grid_clf. best_estimator_ RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "#########################################\n",
      "grid_clf. best_params_ {'max_depth': 7, 'n_estimators': 500}\n",
      "#########################################\n",
      "grid_clf.grid_scores_ [mean: 0.49887, std: 0.08990, params: {'max_depth': 2, 'n_estimators': 20}, mean: 0.50794, std: 0.07653, params: {'max_depth': 2, 'n_estimators': 100}, mean: 0.50567, std: 0.06693, params: {'max_depth': 2, 'n_estimators': 200}, mean: 0.50567, std: 0.06478, params: {'max_depth': 2, 'n_estimators': 500}, mean: 0.49433, std: 0.06919, params: {'max_depth': 5, 'n_estimators': 20}, mean: 0.50567, std: 0.07189, params: {'max_depth': 5, 'n_estimators': 100}, mean: 0.50113, std: 0.06964, params: {'max_depth': 5, 'n_estimators': 200}, mean: 0.49660, std: 0.07529, params: {'max_depth': 5, 'n_estimators': 500}, mean: 0.50340, std: 0.08427, params: {'max_depth': 7, 'n_estimators': 20}, mean: 0.50113, std: 0.07095, params: {'max_depth': 7, 'n_estimators': 100}, mean: 0.50567, std: 0.06794, params: {'max_depth': 7, 'n_estimators': 200}, mean: 0.51474, std: 0.06657, params: {'max_depth': 7, 'n_estimators': 500}, mean: 0.48073, std: 0.07235, params: {'max_depth': 9, 'n_estimators': 20}, mean: 0.49433, std: 0.06257, params: {'max_depth': 9, 'n_estimators': 100}, mean: 0.50794, std: 0.07168, params: {'max_depth': 9, 'n_estimators': 200}, mean: 0.49660, std: 0.07062, params: {'max_depth': 9, 'n_estimators': 500}]\n",
      "#########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(combinedDf[trainCols], \n",
    "                                                                                combinedDf[prediction_label],\n",
    "                                                                                test_size = 0.3,\n",
    "                                                                                random_state = 60)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "clf = RandomForestClassifier() #Initialize with whatever parameters you want to\n",
    "\n",
    "# 10-Fold Cross validation\n",
    "print (np.mean(cross_val_score(clf, scaler.transform(train_features), train_labels, cv=10)))\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators': [20,100,200,500],\n",
    "                 'max_depth': [2, 5, 7, 9]\n",
    "             }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_clf = GridSearchCV(clf, param_grid, cv=10)\n",
    "grid_clf.fit(scaler.transform(train_features), train_labels)\n",
    "\n",
    "print('#########################################')\n",
    "print('grid_clf. best_estimator_',grid_clf. best_estimator_)\n",
    "print('#########################################')\n",
    "print('grid_clf. best_params_',grid_clf. best_params_)\n",
    "print('#########################################')\n",
    "print('grid_clf.grid_scores_',grid_clf.grid_scores_)\n",
    "print('#########################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
